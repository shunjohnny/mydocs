---
title: 2.1 概要
tags:
  - 大規模言語モデル入門Ⅰ
---

## 初めに
---
この本で記載されている内容に関して、  
中途半端に詳しい内容が記載されているため、  
流し読みで理解するには難しく、  
深く理解するには情報が足りない。

よって、まずこの概要の項を借りてtransformerの解説を一通り記載した後に、  
本に記載されている内容の解説を行う。

<br>

## transformerの概要
---
イメージしやすいように、全体の概要を説明する。

<br>

### transformerとは
---
2017年にgoogleが論文[「Attension is All You Need」](https://arxiv.org/pdf/1706.03762)で提案したNNモデル。  
GPT(Generative Pre-trained Transformer)のT。  
元々は機械翻訳モデルだったが、テキスト生成、音声認識、等様々なタスクに使用されている。  
下記の図がtransformerの構造である。

<figure markdown="span">
  ![Image title](<../../images/2.1 概要/2.1 概要_J0133291-1.png>){ width="300" }
  <figcaption>transformerモデルの構造</figcaption>
</figure>



<div class="chat-container">
  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
      さっぱり分からないのだ...<br>
      何をやっているのだ？
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-2.png" alt="ずんだもん" class="avatar">
  </div>

  <!-- 春日部つむぎの左寄せ回答 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      「機械翻訳」を例にして説明するね～✨<br>
      「こたつでみかんを食べる」って日本語を英語に翻訳するときの話ね！<br>
      まず<strong>Encoder</strong>はこの日本語を頭の中で<br>
      「こんな感じの意味だな～！」ってイメージするところなんだよ🍊<br>
      たとえば、左下のinputsに「こたつでみかんを食べる」を入れて、<br>
      その意味を全部理解する感じ！
    </div>
  </div>

  <!-- 2つ目のメッセージボックス -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291-3.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      そんで次に<strong>Decoder</strong>が、そのイメージを使って、<br>
      一つずつ言葉にしていくの！<br>
      右下のoutputsで、最初は「I」から始めて、<br>
      次に「I eat」って続けて、<br>
      「I eat」まで来たら「at」だな～って感じで順番にね👍<br>
      最後に「I eat a mandarin at the kotatsu」が完成するよ！✨
    </div>
  </div>

  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
    <strong>Encoder</strong>がまず全部の意味をわかってから、<br>
    <strong>Decoder</strong>がそれを使って<br>
    ひとつずつ言葉を作るって感じで合ってるのだ？<br>
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-4.png" alt="ずんだもん" class="avatar">
  </div>  
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291-5.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
    そうそう！大体合ってるよ！<br>
    <strong>Encoder</strong>がまず全部の意味をしっかり理解してから、<br>
    <strong>Decoder</strong>がそれを使って順番に言葉を作っていくんだよ👍<br>
    だから、<strong>Encoder</strong>が理解した内容に合わせて、<br>
    <strong>Decoder</strong>が一つずつ言葉を出していく感じなの！😊
    </div>
  </div>  
</div>

<br>

### transformerの強み
---
従来のRNNやLSTMでは、1つの単語を処理した後に次の単語の処理をする「逐次処理」で、  
並列計算を行えず、計算速度が遅い等の問題を抱えていた。  
対してtransformerは下記のような強みを持つ。

| **強み**                     | **詳細**                                                                                                                                             |
|------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| **並列処理が得意**            | Attention機構を使うことで、全ての単語を一度に処理でき、<br>計算が高速。逐次処理が必要なく、GPUが使用でき、<br>長い文章でも効率的に処理できる。              |
| **長距離依存関係の処理**      | Attention機構を使うことで、文中の遠く離れた単語同士の関係も正確に捉えられ、<br>長い文章や複雑な文章も理解できる。                                 |
| **特徴量抽出の強さ**          | Attention機構を使うことで、文中の重要な関係やパターンを自動で学習し、<br>深層で強力な特徴量を抽出。多様な視点から特徴を捉えることができる。              |

<div class="chat-container">
  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
      何かAttention機構が凄いってことは分かったのだ!
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-6.png" alt="ずんだもん" class="avatar">
  </div>

  <!-- 春日部つむぎの左寄せ回答 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291-5.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      うんうん、Attention機構がTransformerのすごいところだよ！✨<br>
      このAttentionをしっかり理解することが、<br>
      Transformerの仕組みをバッチリ掴むためには超大事なの～👌💡<br>
      その前に、まずはTransformer全体の構成をざっくり説明するね！
    </div>
  </div>
</div>

<br>

### transformerの構成
上記に記載どおり、transformerはEncoderとDecoderの二つで構成されており、  
それぞれ処理を行っています。  
両方とも似た処理を行っているので、Encoderで行われている処理が理解できれば、  
Decoderも分かったも同然です。

#### Encoder  

<figure markdown="span">
  ![Image title](<../../images/2.1 概要/2.1 概要_J0133291-7.png>){ width="600" }
  <figcaption>Encoderの構造と各処理の概要</figcaption>
</figure>

<div class="chat-container">
  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
      Multi-Head AttentionがAttention機構のことなのだ?
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-8.png" alt="ずんだもん" class="avatar">
  </div>

  <!-- 春日部つむぎの左寄せ回答 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      そうそう、いい感じだよ～！✨<br>
      でもね、まずはSelf-Attentionっていう基本があってさ～、<br>
      Self-Attentionは、文の中でどの単語が他の単語とどう関係してるか、<br>
      どれくらい重要かを計算して「注意」を向ける仕組みなんだ～！<br>
      例えば「みかん」と「食べる」の関係がしっかり捉えられる感じ🍊🍴。
    </div>
  </div>
  
  <!-- 春日部つむぎの追加説明 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291-3.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      で、Multi-Head Attentionは<br>
      そのSelf-Attentionをもっと強化したバージョン！💪<br>
      複数の視点で文全体を同時に見て、<br>
      より細かい関係までキャッチできるんだよ✨<br>
      各視点が違うところに注目するから、<br>
      より豊かな情報を引き出せるってわけ！
    </div>
  </div>

  <!-- さらにScaled Dot-Product Attentionの補足 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291-3.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      あとね、「Scaled Dot-Product Attention」ていう言葉も出てくるんだけど、<br>
      これはSelf-Attentionを計算するための方法なの！<br>
      色々難しく聞こえるけど、<br>
      要はどの単語にどれだけ注意を向けるかを決めてるんだ😉
    </div>
  </div>

  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
      完全に理解したのだ!
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-9.png" alt="ずんだもん" class="avatar">
  </div>
</div>



#### Decoder
Decoder側のMulti-Head Attentionは基本的な振る舞いは同じだが、  
Multi-Head Attentionの処理が二回登場し、  
Masked Multi-Head Attentionが登場するのと、  
Multi-Head Attentionの入力にEncoderの出力が使用されるという違いがある。

また、Decoder側は最終的な単語を予測するため、  
線形変換とsoftmax関数に通す

<figure markdown="span">
  ![Image title](<../../images/2.1 概要/2.1 概要_J0133291-10.png>){ width="600" }
  <figcaption>Decoderの構造と各処理の概要</figcaption>
</figure>

!!! tips
    Outputsの箇所に関して翻訳した単語を入力とあるが、  
    初めは翻訳した単語がないため、初期値を示す疑似トークンが挿入される。

<div class="chat-container">
  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
      なんか処理が増えているのだ...<br>
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-2.png" alt="ずんだもん" class="avatar">
  </div>

  <!-- 春日部つむぎの左寄せ回答 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      あ～、それね！確かにちょっと増えたけど、<br> 
      増えたのはMulti-Head AttentionとAdd & Normのセットと、<br>
      あとLinearとSoftmaxくらいだからさ、そんなに難しくないよ～👌✨
    </div>
  </div>

  <!-- ずんだもんの右寄せ質問 -->
  <div class="chat right">
    <div class="chat-message zundamon-message">
      (何言ってるのか分からないのだ...)<br>
    </div>
    <img src="../../images/2.1 概要/2.1 概要_J0133291-6.png" alt="ずんだもん" class="avatar">
  </div>

  <!-- 春日部つむぎの左寄せ回答 -->
  <div class="chat left">
    <img src="../../images/2.1 概要/2.1 概要_J0133291-11.png" alt="春日部つむぎ" class="avatar">
    <div class="chat-message tsumugi-message">
      次の2.2の項でEncoderについて詳しく説明するからさ～、<br>
      今は「ちょっと違うかも？」くらいでOKだよ！気楽にね～😊✨
    </div>
  </div>
</div>



## 参考文献
---

### 動画:material-youtube:  

- 視覚的に理解したい場合
<div style="text-align: center;">
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/KlZ-QmPteqM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<div style="text-align: center; margin-top: 10px;">
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/j3_VgCt18fA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<div style="text-align: center; margin-top: 10px;">
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/mmWuqh7XDx4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

- 数式を追いながら理解したい場合
<div style="text-align: center; margin-top: 10px;">
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/50XvMaWhiTY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<div style="text-align: center; margin-top: 10px;">
  <iframe width="80%" height="315" src="https://www.youtube.com/embed/FFoLqib6u-0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>



### webサイト:material-web:  
[Multi-Head AttentionとScaled Dot-Product Attentionの全て：Transformerの核心を徹底解説](https://www.nomuyu.com/multi-head-attention/)